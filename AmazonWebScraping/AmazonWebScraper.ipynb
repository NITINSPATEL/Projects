{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f236cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import datetime\n",
    "import smtplib\n",
    "import csv \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b531b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                             149\n",
      "                             \n",
      "                              .\n",
      "                             \n",
      "\n",
      "\n",
      "              Lapster Gel Mouse pad with Wrist Rest, Gaming Mouse Pad with Lycra Cloth Nonslip for Laptop, Computer, Home & Office (Black)\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "# Connecting to Website and pull in data\n",
    "\n",
    "URL = 'https://www.amazon.in/Lapster-Gaming-Nonslip-Laptop-Computer/dp/B0B2PQL5N3/?_encoding=UTF8&ref_=pd_hp_d_btf_pd_pss_gwp_d_0'\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "page = requests.get(URL, headers=headers)\n",
    "\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
    "\n",
    "title = soup2.find('span', id='productTitle').get_text()\n",
    "price = soup2.find('span', class_='a-price-whole').get_text()\n",
    "\n",
    "print(price)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6f7d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lapster Gel Mouse pad with Wrist Rest, Gaming Mouse Pad with Lycra Cloth Nonslip for Laptop, Computer, Home & Office (Black)\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "# Cleaning up the data a little bit\n",
    "\n",
    "price = price.strip()[0:3]\n",
    "title = title.strip()\n",
    "\n",
    "print(title)\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f021c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-07\n"
     ]
    }
   ],
   "source": [
    "# Creating a Timestamp for your output to track when data was collected\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "print(today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14d703ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating CSV and write headers and data into the file\n",
    "\n",
    "\n",
    "header = ['Title', 'Price', 'Date']\n",
    "data = [title, price, today]\n",
    "\n",
    "\n",
    "with open('AmazonWebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d07eeb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Price        Date\n",
      "0  Lapster Gel Mouse pad with Wrist Rest, Gaming ...    149  2024-07-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(r'AmazonWebScraperDataset.csv')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b05c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are appending data to the csv\n",
    "\n",
    "with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e95b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all of the above code into one function , used for regular price tracking\n",
    "\n",
    "\n",
    "def check_price():\n",
    "    URL = 'https://www.amazon.in/Lapster-Gaming-Nonslip-Laptop-Computer/dp/B0B2PQL5N3/?_encoding=UTF8&ref_=pd_hp_d_btf_pd_pss_gwp_d_0'\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    page = requests.get(URL, headers=headers)\n",
    "\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
    "\n",
    "    title = soup2.find('span', id='productTitle').get_text()\n",
    "    price = soup2.find('span', class_='a-price-whole').get_text()\n",
    "\n",
    "    price = price.strip()[0:3]\n",
    "    title = title.strip()\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    # if int(price) < 120:\n",
    "    #     send_mail()\n",
    "\n",
    "    header = ['Title', 'Price', 'Date']\n",
    "    data = [title, price, today]\n",
    "\n",
    "    with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c72f2c4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Runs check_price after a set time and inputs data into your CSV\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mcheck_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[47], line 13\u001b[0m, in \u001b[0;36mcheck_price\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m page \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(URL, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     11\u001b[0m soup1 \u001b[38;5;241m=\u001b[39m BeautifulSoup(page\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m soup2 \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprettify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m title \u001b[38;5;241m=\u001b[39m soup2\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproductTitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text()\n\u001b[1;32m     16\u001b[0m price \u001b[38;5;241m=\u001b[39m soup2\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma-price-whole\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    378\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# when there's an error in the doctype declaration.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/html/parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m startswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, i):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m starttagopen\u001b[38;5;241m.\u001b[39mmatch(rawdata, i): \u001b[38;5;66;03m# < + letter\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[1;32m    172\u001b[0m         k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[0;32m/usr/lib/python3.10/html/parser.py:344\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_cdata_mode(tag)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:137\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#print(\"START\", name)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m sourceline, sourcepos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetpos()\n\u001b[0;32m--> 137\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msourceline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourceline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43msourcepos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourcepos\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mand\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mis_empty_element \u001b[38;5;129;01mand\u001b[39;00m handle_empty_element:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# events for tags of this name.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:742\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by the tree builder when a new tag is encountered.\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03m:param name: Name of the tag.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03mdon't call handle_endtag.\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# print(\"Start tag %s: %s\" % (name, attrs))\u001b[39;00m\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    746\u001b[0m          \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39msearch_tag(name, attrs))):\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:618\u001b[0m, in \u001b[0;36mBeautifulSoup.endData\u001b[0;34m(self, containerClass)\u001b[0m\n\u001b[1;32m    616\u001b[0m containerClass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstring_container(containerClass)\n\u001b[1;32m    617\u001b[0m o \u001b[38;5;241m=\u001b[39m containerClass(current_data)\n\u001b[0;32m--> 618\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject_was_parsed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:646\u001b[0m, in \u001b[0;36mBeautifulSoup.object_was_parsed\u001b[0;34m(self, o, parent, most_recent_element)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Check if we are inserting into an already parsed node.\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[0;32m--> 646\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_linkage_fixer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:670\u001b[0m, in \u001b[0;36mBeautifulSoup._linkage_fixer\u001b[0;34m(self, el)\u001b[0m\n\u001b[1;32m    667\u001b[0m child\u001b[38;5;241m.\u001b[39mnext_sibling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# This index is a tag, dig deeper for a \"last descendant\"\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTag\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m child\u001b[38;5;241m.\u001b[39mcontents:\n\u001b[1;32m    671\u001b[0m     descendant \u001b[38;5;241m=\u001b[39m child\u001b[38;5;241m.\u001b[39m_last_descendant(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# As the final step, link last descendant. It should be linked\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# to the parent's next sibling (if found), else walk up the chain\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# and find a parent with a sibling. It should have no next sibling.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running check_price after a set time , 1 day , and inputs data into your CSV\n",
    "\n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00af7126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Price        Date\n",
      "0  Lapster Gel Mouse pad with Wrist Rest, Gaming ...    149  2024-07-07\n",
      "1  Lapster Gel Mouse pad with Wrist Rest, Gaming ...    149  2024-07-07\n",
      "2  Lapster Gel Mouse pad with Wrist Rest, Gaming ...    149  2024-07-07\n",
      "3  Lapster Gel Mouse pad with Wrist Rest, Gaming ...    149  2024-07-07\n",
      "4  Lapster Gel Mouse pad with Wrist Rest, Gaming ...    149  2024-07-07\n",
      "5  Lapster Gel Mouse pad with Wrist Rest, Gaming ...    149  2024-07-07\n",
      "6  Lapster Gel Mouse pad with Wrist Rest, Gaming ...    149  2024-07-07\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'AmazonWebScraperDataset.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d14fce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  when a price hits below a certain level , Rs 120 , we can automate e-mail sending\n",
    "\n",
    "def send_mail():\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n",
    "    server.ehlo()\n",
    "    #server.starttls()\n",
    "    server.ehlo()\n",
    "    server.login('nitinsp27@gmail.com','xxxxxxxxxx')\n",
    "    \n",
    "    subject = \"The Mouse you want is below Rs120! Now is your chance to buy!\"\n",
    "    body = \"Hi , Nitin, This is the moment we have been waiting for. Now is your chance to pick up the shirt of your dreams. Don't mess it up! Link here: https://www.amazon.in/Lapster-Gaming-Nonslip-Laptop-Computer/dp/B0B2PQL5N3/?_encoding=UTF8&ref_=pd_hp_d_btf_pd_pss_gwp_d_0\"\n",
    "   \n",
    "    msg = f\"Subject: {subject}\\n\\n{body}\"\n",
    "    \n",
    "    server.sendmail(\n",
    "        'nitinsp27@gmail.com',\n",
    "        msg\n",
    "     \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
